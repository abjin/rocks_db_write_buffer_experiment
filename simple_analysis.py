#!/usr/bin/env python3
"""
RocksDB Write Buffer ì‹¤í—˜ ê²°ê³¼ ê°„ë‹¨ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def parse_result_file(file_path):
    """db_bench ê²°ê³¼ íŒŒì¼ì—ì„œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        # íŒŒì¼ëª…ì—ì„œ ì„¤ì • ì •ë³´ ì¶”ì¶œ
        filename = Path(file_path).stem
        parts = filename.split('_')
        
        if len(parts) >= 5:
            benchmark_type = parts[0]
            write_buffer_size = int(parts[1])
            max_write_buffer_number = int(parts[2])
            min_write_buffer_number_to_merge = int(parts[3])
            iteration = int(parts[4].replace('iter', ''))
        else:
            return None
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì¶œ
        throughput = 0
        latency = 0
        
        # fillrandom, readrandom, overwrite ê²°ê³¼ ë¼ì¸ ì°¾ê¸°
        pattern = rf'{benchmark_type}\s*:\s*([\d.]+)\s*micros/op\s*([\d.]+)\s*ops/sec'
        match = re.search(pattern, content)
        
        if match:
            latency = float(match.group(1))
            throughput = float(match.group(2))
        
        return {
            'benchmark_type': benchmark_type,
            'write_buffer_size_mb': write_buffer_size // (1024 * 1024),
            'max_write_buffer_number': max_write_buffer_number,
            'min_write_buffer_number_to_merge': min_write_buffer_number_to_merge,
            'iteration': iteration,
            'throughput': throughput,
            'latency_us': latency
        }
    
    except Exception as e:
        print(f"íŒŒì¼ íŒŒì‹± ì—ëŸ¬ {file_path}: {e}")
        return None

def load_all_results(results_dir="write_buffer_experiment/results"):
    """ëª¨ë“  ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
    results = []
    results_path = Path(results_dir)
    
    if not results_path.exists():
        print(f"ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {results_dir}")
        return pd.DataFrame()
    
    for file_path in results_path.glob("*.txt"):
        result = parse_result_file(file_path)
        if result and result['throughput'] > 0:  # ìœ íš¨í•œ ê²°ê³¼ë§Œ
            results.append(result)
    
    if not results:
        print("ìœ íš¨í•œ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    df = pd.DataFrame(results)
    print(f"ì´ {len(df)}ê°œì˜ ìœ íš¨í•œ ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ")
    return df

def create_basic_analysis(df):
    """ê¸°ë³¸ ë¶„ì„ ë° ì‹œê°í™”"""
    if df.empty:
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("write_buffer_experiment/analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. ê¸°ë³¸ í†µê³„
    print("\n=== ê¸°ë³¸ í†µê³„ ===")
    print(f"ë²¤ì¹˜ë§ˆí¬ íƒ€ì…: {df['benchmark_type'].unique()}")
    print(f"Write Buffer í¬ê¸°: {sorted(df['write_buffer_size_mb'].unique())}MB")
    print(f"ì²˜ë¦¬ëŸ‰ ë²”ìœ„: {df['throughput'].min():.0f} ~ {df['throughput'].max():.0f} ops/sec")
    print(f"ì§€ì—°ì‹œê°„ ë²”ìœ„: {df['latency_us'].min():.2f} ~ {df['latency_us'].max():.2f} Î¼s")
    
    # 2. fillrandom ê¸°ë³¸ ì„¤ì • ë¶„ì„
    fillrandom_basic = df[
        (df['benchmark_type'] == 'fillrandom') & 
        (df['max_write_buffer_number'] == 2) &
        (df['min_write_buffer_number_to_merge'] == 1)
    ]
    
    if not fillrandom_basic.empty:
        print("\n=== fillrandom ê¸°ë³¸ ì„¤ì • (2,1) ê²°ê³¼ ===")
        summary = fillrandom_basic.groupby('write_buffer_size_mb').agg({
            'throughput': ['mean', 'std'],
            'latency_us': ['mean', 'std']
        }).round(2)
        print(summary)
        
        # ìµœì  ì„¤ì • ì°¾ê¸°
        best_throughput = fillrandom_basic.groupby('write_buffer_size_mb')['throughput'].mean()
        optimal_size = best_throughput.idxmax()
        optimal_throughput = best_throughput.max()
        
        print(f"\nìµœì  Write Buffer Size: {optimal_size}MB")
        print(f"ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {optimal_throughput:.0f} ops/sec")
    
    # 3. ê°„ë‹¨í•œ ì‹œê°í™”
    plt.style.use('default')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('RocksDB Write Buffer ì‹¤í—˜ ê²°ê³¼', fontsize=16, fontweight='bold')
    
    # 3-1. Write Buffer Size vs Throughput (fillrandom)
    if not fillrandom_basic.empty:
        throughput_avg = fillrandom_basic.groupby('write_buffer_size_mb')['throughput'].mean()
        ax1.plot(throughput_avg.index, throughput_avg.values, 'o-', linewidth=2, markersize=8)
        ax1.set_title('Throughput vs Write Buffer Size (fillrandom)')
        ax1.set_xlabel('Write Buffer Size (MB)')
        ax1.set_ylabel('Throughput (ops/sec)')
        ax1.grid(True, alpha=0.3)
        
        # ìµœì ì  í‘œì‹œ
        ax1.axvline(x=optimal_size, color='red', linestyle='--', alpha=0.7)
        ax1.text(optimal_size, optimal_throughput, f'ìµœì : {optimal_size}MB', 
                rotation=90, verticalalignment='bottom', color='red')
    
    # 3-2. Latency vs Write Buffer Size
    if not fillrandom_basic.empty:
        latency_avg = fillrandom_basic.groupby('write_buffer_size_mb')['latency_us'].mean()
        ax2.plot(latency_avg.index, latency_avg.values, 's-', linewidth=2, markersize=8, color='orange')
        ax2.set_title('Latency vs Write Buffer Size (fillrandom)')
        ax2.set_xlabel('Write Buffer Size (MB)')
        ax2.set_ylabel('Latency (Î¼s)')
        ax2.grid(True, alpha=0.3)
    
    # 3-3. ë²¤ì¹˜ë§ˆí¬ íƒ€ì…ë³„ ë¹„êµ
    benchmark_comparison = df.groupby(['benchmark_type', 'write_buffer_size_mb'])['throughput'].mean().unstack(level=0)
    if not benchmark_comparison.empty:
        benchmark_comparison.plot(kind='bar', ax=ax3, width=0.8)
        ax3.set_title('Throughput by Benchmark Type')
        ax3.set_xlabel('Write Buffer Size (MB)')
        ax3.set_ylabel('Throughput (ops/sec)')
        ax3.legend(title='Benchmark Type')
        ax3.tick_params(axis='x', rotation=45)
    
    # 3-4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
    if not fillrandom_basic.empty:
        efficiency = fillrandom_basic.groupby('write_buffer_size_mb')['throughput'].mean() / fillrandom_basic.groupby('write_buffer_size_mb')['write_buffer_size_mb'].first()
        ax4.bar(efficiency.index, efficiency.values, alpha=0.7, color='green')
        ax4.set_title('Memory Efficiency (Throughput/MB)')
        ax4.set_xlabel('Write Buffer Size (MB)')
        ax4.set_ylabel('Efficiency (ops/sec/MB)')
        ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'simple_analysis.png', dpi=300, bbox_inches='tight')
    print(f"\nì‹œê°í™” ì €ì¥: {output_dir / 'simple_analysis.png'}")
    
    # 4. CSV ì €ì¥
    df.to_csv(output_dir / 'simple_results.csv', index=False)
    print(f"ê²°ê³¼ ì €ì¥: {output_dir / 'simple_results.csv'}")

def main():
    print("ğŸš€ RocksDB Write Buffer ì‹¤í—˜ ê°„ë‹¨ ë¶„ì„ ì‹œì‘")
    
    # ê²°ê³¼ ë¡œë“œ
    df = load_all_results()
    
    if df.empty:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¶„ì„ ì‹¤í–‰
    create_basic_analysis(df)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 