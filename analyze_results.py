#!/usr/bin/env python3
"""
RocksDB Write Buffer ìµœì í™” ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (í‰ê°€í‘œ ìµœì í™” ë²„ì „)
ì‘ì„±ì: ì»´í“¨í„°ê³µí•™ê³¼ 4í•™ë…„
ëª©ì : ì‹¤í—˜ ê²°ê³¼ ë°ì´í„° íŒŒì‹±, ë¶„ì„ ë° ì‹œê°í™” (10-12ë¶„ ë°œí‘œìš© ìµœì í™”)
"""

import os
import re
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
from collections import defaultdict
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

# ë°œí‘œìš© ì‹œê°í™” ì„¤ì • (í‰ê°€í‘œ ìµœì í™”)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['font.size'] = 13
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['xtick.labelsize'] = 11
plt.rcParams['ytick.labelsize'] = 11

class RocksDBResultAnalyzer:
    """RocksDB ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ í´ë˜ìŠ¤ (í‰ê°€í‘œ ìµœì í™”)"""
    
    def __init__(self, results_dir="write_buffer_experiment/results"):
        self.results_dir = Path(results_dir)
        self.logs_dir = Path("write_buffer_experiment/logs")
        self.output_dir = Path("write_buffer_experiment/analysis")
        self.output_dir.mkdir(exist_ok=True)
        
        # ë°œí‘œìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ì‹œê°ì  ë§¤ë ¥ í–¥ìƒ)
        self.colors = {
            'primary': '#2E86AB',
            'secondary': '#A23B72', 
            'accent': '#F18F01',
            'warning': '#C73E1D',
            'success': '#5FAD41',
            'purple': '#8B5CF6'
        }
        
        # ê²°ê³¼ ì €ì¥ìš© ë°ì´í„°
        self.results_data = []
        self.summary_stats = {}
        self.insights = []  # ë°œí‘œìš© ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        print("ğŸ” RocksDB Write Buffer ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ê¸° ì‹œì‘ (í‰ê°€í‘œ ìµœì í™” ë²„ì „)")
        print("ğŸ“Š ë°œí‘œ ì‹œê°„: 10-12ë¶„ ìµœì í™”")
        
    def parse_db_bench_output(self, file_path):
        """db_bench ì¶œë ¥ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {e}")
            return None
            
        metrics = {}
        
        # ì²˜ë¦¬ëŸ‰ (ops/sec) ì¶”ì¶œ - ë” ì •í™•í•œ íŒ¨í„´
        throughput_patterns = [
            r'(\d+)\s+ops/sec',
            r'(\d+\.\d+)\s+MB/s.*?(\d+)\s+ops/sec',
            r'fillrandom.*?(\d+)\s+ops/sec'
        ]
        
        for pattern in throughput_patterns:
            match = re.search(pattern, content)
            if match:
                metrics['throughput'] = float(match.group(-1))  # ë§ˆì§€ë§‰ ê·¸ë£¹ ì‚¬ìš©
                break
        
        # ì§€ì—°ì‹œê°„ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        avg_latency_match = re.search(r'Average:\s+([\d.]+)', content)
        if avg_latency_match:
            metrics['avg_latency_us'] = float(avg_latency_match.group(1))
            
        # P99 ì§€ì—°ì‹œê°„ ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        percentile_patterns = [
            r'Percentiles: P50: ([\d.]+) P95: ([\d.]+) P99: ([\d.]+)',
            r'P50: ([\d.]+).*?P95: ([\d.]+).*?P99: ([\d.]+)',
            r'99%\s+([\d.]+)'
        ]
        
        for pattern in percentile_patterns:
            match = re.search(pattern, content)
            if match:
                if len(match.groups()) >= 3:
                    metrics['p50_latency_us'] = float(match.group(1))
                    metrics['p95_latency_us'] = float(match.group(2))
                    metrics['p99_latency_us'] = float(match.group(3))
                else:
                    metrics['p99_latency_us'] = float(match.group(1))
                break
        
        # Write amplification ë° ê¸°íƒ€ ë©”íŠ¸ë¦­
        wa_match = re.search(r'Write amplification:\s+([\d.]+)', content)
        if wa_match:
            metrics['write_amplification'] = float(wa_match.group(1))
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë‹¤ì–‘í•œ íŒ¨í„´ ëŒ€ì‘)
        mem_patterns = [
            r'Block cache size:\s+([\d.]+)\s*MB',
            r'Cache usage:\s+([\d.]+)\s*MB',
            r'Total memory usage:\s+([\d.]+)\s*MB'
        ]
        
        for pattern in mem_patterns:
            match = re.search(pattern, content)
            if match:
                metrics['memory_usage_mb'] = float(match.group(1))
                break
        
        # Compaction í†µê³„
        compaction_match = re.search(r'Compactions.*?Level\s+Files\s+Size', content, re.DOTALL)
        if compaction_match:
            level0_match = re.search(r'L0\s+(\d+)', content)
            if level0_match:
                metrics['l0_files'] = int(level0_match.group(1))
        
        return metrics
    
    def parse_filename(self, filename):
        """íŒŒì¼ëª…ì—ì„œ ì‹¤í—˜ ì„¤ì • ì •ë³´ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        # ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›
        patterns = [
            r'(\w+)_(\d+)_(\d+)_(\d+)_iter(\d+)\.txt',
            r'(\w+)_(\d+)_(\d+)_(\d+)_mixed_(\w+)\.txt'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, filename)
            if match:
                if len(match.groups()) == 5:
                    # ì¼ë°˜ ì‹¤í—˜
                    benchmark_type = match.group(1)
                    write_buffer_size = int(match.group(2))
                    max_write_buffer_number = int(match.group(3))
                    min_write_buffer_number_to_merge = int(match.group(4))
                    iteration = int(match.group(5))
                    workload_pattern = None
                elif len(match.groups()) == 6:
                    # í˜¼í•© ì›Œí¬ë¡œë“œ
                    benchmark_type = match.group(1)
                    write_buffer_size = int(match.group(2))
                    max_write_buffer_number = int(match.group(3))
                    min_write_buffer_number_to_merge = int(match.group(4))
                    iteration = int(match.group(5))
                    workload_pattern = match.group(6)
                else:
                    continue
                
                # í¬ê¸°ë¥¼ MBë¡œ ë³€í™˜
                write_buffer_size_mb = write_buffer_size // (1024 * 1024)
                
                return {
                    'benchmark_type': benchmark_type,
                    'write_buffer_size_bytes': write_buffer_size,
                    'write_buffer_size_mb': write_buffer_size_mb,
                    'max_write_buffer_number': max_write_buffer_number,
                    'min_write_buffer_number_to_merge': min_write_buffer_number_to_merge,
                    'iteration': iteration,
                    'workload_pattern': workload_pattern
                }
        
        return None
    
    def load_all_results(self):
        """ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ë° íŒŒì‹± (ê°œì„ ëœ ë²„ì „)"""
        print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ë¡œë”© ì¤‘...")
        
        if not self.results_dir.exists():
            print(f"âŒ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.results_dir}")
            return
            
        result_files = list(self.results_dir.glob("*.txt"))
        print(f"ğŸ“ ì´ {len(result_files)}ê°œì˜ ê²°ê³¼ íŒŒì¼ ë°œê²¬")
        
        # íŒŒì‹± í†µê³„
        successful_parses = 0
        failed_parses = 0
        
        for file_path in result_files:
            # íŒŒì¼ëª…ì—ì„œ ì‹¤í—˜ ì„¤ì • ì¶”ì¶œ
            config = self.parse_filename(file_path.name)
            if not config:
                print(f"âš ï¸  íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨: {file_path.name}")
                failed_parses += 1
                continue
                
            # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì‹±
            metrics = self.parse_db_bench_output(file_path)
            if not metrics:
                print(f"âš ï¸  ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {file_path.name}")
                failed_parses += 1
                continue
            
            # ë°ì´í„° ê²°í•©
            result = {**config, **metrics}
            self.results_data.append(result)
            successful_parses += 1
            
        print(f"âœ… {successful_parses}ê°œ ì„±ê³µ, {failed_parses}ê°œ ì‹¤íŒ¨")
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        if self.results_data:
            self.df = pd.DataFrame(self.results_data)
            print("ğŸ“ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ")
            self.save_raw_data()
            self.generate_basic_insights()
        else:
            print("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def generate_basic_insights(self):
        """ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ë°œí‘œìš©)"""
        if self.df.empty:
            return
        
        print("ğŸ§  ë°œí‘œìš© ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
        
        # 1. ìµœê³  ì„±ëŠ¥ ì„¤ì • ì°¾ê¸°
        best_throughput = self.df.loc[self.df['throughput'].idxmax()]
        self.insights.append({
            'type': 'performance_peak',
            'title': 'ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ì„¤ì •',
            'content': f"{best_throughput['write_buffer_size_mb']}MB ë²„í¼ì—ì„œ {best_throughput['throughput']:,.0f} ops/sec ë‹¬ì„±"
        })
        
        # 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„ì„
        self.df['memory_efficiency'] = self.df['throughput'] / (self.df['write_buffer_size_mb'] * self.df['max_write_buffer_number'])
        best_efficiency = self.df.loc[self.df['memory_efficiency'].idxmax()]
        self.insights.append({
            'type': 'efficiency_peak',
            'title': 'ìµœê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±',
            'content': f"{best_efficiency['write_buffer_size_mb']}MB ì„¤ì •ì—ì„œ MBë‹¹ {best_efficiency['memory_efficiency']:.0f} ops/sec"
        })
        
        # 3. ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
        fillrandom_data = self.df[self.df['benchmark_type'] == 'fillrandom']
        if not fillrandom_data.empty:
            corr = fillrandom_data['write_buffer_size_mb'].corr(fillrandom_data['throughput'])
            if corr > 0.5:
                trend = "ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„"
            elif corr < -0.5:
                trend = "ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„"
            else:
                trend = "ë¹„ì„ í˜• ê´€ê³„"
            
            self.insights.append({
                'type': 'trend_analysis',
                'title': 'Write Buffer í¬ê¸°ì™€ ì„±ëŠ¥ ê´€ê³„',
                'content': f"ìƒê´€ê³„ìˆ˜ {corr:.3f}: {trend} í™•ì¸"
            })
    
    def save_raw_data(self):
        """ì›ì‹œ ë°ì´í„°ë¥¼ CSV ë° JSONìœ¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        csv_path = self.output_dir / f"experiment_results_{timestamp}.csv"
        json_path = self.output_dir / f"experiment_results_{timestamp}.json"
        
        self.df.to_csv(csv_path, index=False)
        self.df.to_json(json_path, orient='records', indent=2)
        
        # ìµœì‹  íŒŒì¼ ë§í¬ ìƒì„±
        latest_csv = self.output_dir / "latest_results.csv"
        latest_json = self.output_dir / "latest_results.json"
        
        self.df.to_csv(latest_csv, index=False)
        self.df.to_json(latest_json, orient='records', indent=2)
        
        print(f"ğŸ’¾ ì›ì‹œ ë°ì´í„° ì €ì¥: {csv_path}")
    
    def calculate_statistics(self):
        """ì‹¤í—˜ ê²°ê³¼ í†µê³„ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        print("ğŸ“Š í†µê³„ ë¶„ì„ ì¤‘...")
        
        if self.df.empty:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°˜ë³µ ì‹¤í—˜ ê²°ê³¼ í‰ê·  ê³„ì‚°
        groupby_cols = ['benchmark_type', 'write_buffer_size_mb', 'max_write_buffer_number', 'min_write_buffer_number_to_merge']
        
        # ë” ë§ì€ í†µê³„ ë©”íŠ¸ë¦­ ê³„ì‚°
        agg_functions = {
            'throughput': ['mean', 'std', 'min', 'max'],
            'avg_latency_us': ['mean', 'std', 'min', 'max'],
            'p99_latency_us': ['mean', 'std', 'min', 'max'],
        }
        
        # write_amplificationì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
        if 'write_amplification' in self.df.columns:
            agg_functions['write_amplification'] = ['mean', 'std']
        
        self.summary_stats = self.df.groupby(groupby_cols).agg(agg_functions).round(2)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        self.summary_stats.columns = ['_'.join(col).strip() for col in self.summary_stats.columns.values]
        self.summary_stats = self.summary_stats.reset_index()
        
        # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ë°œí‘œìš© ì¶”ê°€ í†µê³„)
        for metric in ['throughput', 'avg_latency_us', 'p99_latency_us']:
            if f'{metric}_mean' in self.summary_stats.columns and f'{metric}_std' in self.summary_stats.columns:
                # 95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (t-ë¶„í¬ ê°€ì •, df=2 for 3 iterations)
                from scipy import stats
                t_value = stats.t.ppf(0.975, df=2)  # 95% ì‹ ë¢°êµ¬ê°„
                margin_error = t_value * self.summary_stats[f'{metric}_std'] / np.sqrt(3)
                self.summary_stats[f'{metric}_ci_lower'] = self.summary_stats[f'{metric}_mean'] - margin_error
                self.summary_stats[f'{metric}_ci_upper'] = self.summary_stats[f'{metric}_mean'] + margin_error
        
        # ìš”ì•½ í†µê³„ ì €ì¥
        summary_path = self.output_dir / "summary_statistics.csv"
        self.summary_stats.to_csv(summary_path, index=False)
        
        print(f"ğŸ“Š ìš”ì•½ í†µê³„ ì €ì¥: {summary_path}")
    
    def create_presentation_visualizations(self):
        """ë°œí‘œìš© ì‹œê°í™” ìƒì„± (í‰ê°€í‘œ ìµœì í™”)"""
        print("ğŸ“ˆ ë°œí‘œìš© ì‹œê°í™” ìƒì„± ì¤‘...")
        
        if self.df.empty:
            return
        
        # ë°œí‘œìš© ìŠ¤íƒ€ì¼ ì„¤ì •
        sns.set_style("whitegrid")
        sns.set_palette("husl")
        
        # 1. í•µì‹¬ ë°œê²¬ì‚¬í•­ ëŒ€ì‹œë³´ë“œ (ë°œí‘œ ë©”ì¸ ìŠ¬ë¼ì´ë“œìš©)
        self.create_main_dashboard()
        
        # 2. Write Buffer Size ì˜í–¥ ë¶„ì„ (ìƒì„¸ ë¶„ì„ìš©)
        self.create_buffer_size_analysis()
        
        # 3. ì„±ëŠ¥ vs ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„ (ë…ì°½ì  ì ‘ê·¼)
        self.create_tradeoff_analysis()
        
        # 4. íŒŒë¼ë¯¸í„° ì¡°í•© ìµœì í™” (ì‹¬í™” ë¶„ì„)
        self.create_parameter_optimization()
        
        print("ğŸ¨ ëª¨ë“  ë°œí‘œìš© ì‹œê°í™” ì™„ë£Œ")
    
    def create_main_dashboard(self):
        """ë©”ì¸ ëŒ€ì‹œë³´ë“œ ìƒì„± (ë°œí‘œ í•µì‹¬ ìŠ¬ë¼ì´ë“œ)"""
        fig = plt.figure(figsize=(20, 12))
        
        # 2x3 ê·¸ë¦¬ë“œ ì„¤ì •
        gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)
        
        # fillrandom ê¸°ì¤€ ê¸°ë³¸ ì„¤ì • ë°ì´í„°
        main_data = self.df[
            (self.df['benchmark_type'] == 'fillrandom') & 
            (self.df['max_write_buffer_number'] == 2) &
            (self.df['min_write_buffer_number_to_merge'] == 1)
        ]
        
        if main_data.empty:
            print("âš ï¸ ë©”ì¸ ëŒ€ì‹œë³´ë“œìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê·¸ë£¹ë³„ í‰ê·  ê³„ì‚°
        grouped = main_data.groupby('write_buffer_size_mb').agg({
            'throughput': ['mean', 'std'],
            'p99_latency_us': ['mean', 'std'],
            'write_amplification': 'mean' if 'write_amplification' in main_data.columns else lambda x: 1
        }).reset_index()
        
        # ì»¬ëŸ¼ëª… ë‹¨ìˆœí™”
        grouped.columns = ['buffer_size', 'throughput_mean', 'throughput_std', 'latency_mean', 'latency_std', 'write_amp']
        
        # 1. í•µì‹¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ (í° ê·¸ë˜í”„)
        ax1 = fig.add_subplot(gs[0, :2])
        
        # ì²˜ë¦¬ëŸ‰ ê·¸ë˜í”„ (ì£¼ì¶•)
        line1 = ax1.plot(grouped['buffer_size'], grouped['throughput_mean'], 
                        marker='o', linewidth=3, markersize=10, 
                        color=self.colors['primary'], label='Throughput')
        ax1.fill_between(grouped['buffer_size'], 
                        grouped['throughput_mean'] - grouped['throughput_std'],
                        grouped['throughput_mean'] + grouped['throughput_std'],
                        alpha=0.3, color=self.colors['primary'])
        
        # ìµœì ì  í‘œì‹œ
        max_idx = grouped['throughput_mean'].idxmax()
        optimal_size = grouped.loc[max_idx, 'buffer_size']
        optimal_throughput = grouped.loc[max_idx, 'throughput_mean']
        
        ax1.annotate(f'ìµœì ì \n{optimal_size}MB\n{optimal_throughput:,.0f} ops/sec', 
                    xy=(optimal_size, optimal_throughput),
                    xytext=(optimal_size + 20, optimal_throughput + 5000),
                    arrowprops=dict(arrowstyle='->', color='red', lw=2),
                    fontsize=14, color='red', fontweight='bold',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7))
        
        ax1.set_title('RocksDB Write Buffer ìµœì í™”: í•µì‹¬ ì„±ëŠ¥ ë¶„ì„', fontsize=18, fontweight='bold', pad=20)
        ax1.set_xlabel('Write Buffer Size (MB)', fontsize=14)
        ax1.set_ylabel('Throughput (ops/sec)', fontsize=14, color=self.colors['primary'])
        ax1.tick_params(axis='y', labelcolor=self.colors['primary'])
        ax1.grid(True, alpha=0.3)
        
        # ì§€ì—°ì‹œê°„ ê·¸ë˜í”„ (ë³´ì¡°ì¶•)
        ax1_twin = ax1.twinx()
        line2 = ax1_twin.plot(grouped['buffer_size'], grouped['latency_mean'], 
                             marker='s', linewidth=3, markersize=8, 
                             color=self.colors['secondary'], label='P99 Latency')
        ax1_twin.set_ylabel('P99 Latency (Î¼s)', fontsize=14, color=self.colors['secondary'])
        ax1_twin.tick_params(axis='y', labelcolor=self.colors['secondary'])
        
        # ë²”ë¡€ í†µí•©
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax1.legend(lines, labels, loc='upper left', fontsize=12)
        
        # 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (ì›í˜• ì°¨íŠ¸)
        ax2 = fig.add_subplot(gs[0, 2])
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³„ì‚°
        grouped['memory_total'] = grouped['buffer_size'] * 2  # max_write_buffer_number = 2
        grouped['efficiency'] = grouped['throughput_mean'] / grouped['memory_total']
        
        sizes = grouped['efficiency']
        labels = [f'{size}MB\n{eff:.0f} ops/MB' for size, eff in 
                 zip(grouped['buffer_size'], grouped['efficiency'])]
        colors_pie = plt.cm.Spectral(np.linspace(0, 1, len(sizes)))
        
        wedges, texts, autotexts = ax2.pie(sizes, labels=labels, autopct='%1.1f%%',
                                          colors=colors_pie, startangle=90)
        ax2.set_title('ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„í¬', fontsize=14, fontweight='bold')
        
        # 3. ë²¤ì¹˜ë§ˆí¬ íƒ€ì…ë³„ ë¹„êµ (í•˜ë‹¨ ì™¼ìª½)
        ax3 = fig.add_subplot(gs[1, 0])
        
        comparison_data = self.df[
            (self.df['max_write_buffer_number'] == 2) &
            (self.df['min_write_buffer_number_to_merge'] == 1)
        ]
        
        if not comparison_data.empty:
            pivot_data = comparison_data.groupby(['benchmark_type', 'write_buffer_size_mb'])['throughput'].mean().unstack()
            
            if not pivot_data.empty:
                pivot_data.plot(kind='bar', ax=ax3, color=[self.colors['primary'], self.colors['accent'], self.colors['success']])
                ax3.set_title('ë²¤ì¹˜ë§ˆí¬ íƒ€ì…ë³„ ì„±ëŠ¥ ë¹„êµ', fontsize=14, fontweight='bold')
                ax3.set_xlabel('Benchmark Type')
                ax3.set_ylabel('Throughput (ops/sec)')
                ax3.tick_params(axis='x', rotation=45)
                ax3.legend(title='Buffer Size (MB)', bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 4. ì‹¤í—˜ í†µê³„ ìš”ì•½ (í•˜ë‹¨ ì¤‘ì•™)
        ax4 = fig.add_subplot(gs[1, 1])
        ax4.axis('off')
        
        # ì£¼ìš” í†µê³„ í…ìŠ¤íŠ¸
        stats_text = f"""
        ğŸ“Š ì‹¤í—˜ ìš”ì•½ í†µê³„
        
        âœ… ì´ ì‹¤í—˜ íšŸìˆ˜: {len(self.df)}ê°œ
        ğŸ¯ ìµœê³  ì„±ëŠ¥: {optimal_throughput:,.0f} ops/sec
        ğŸ’¾ ìµœì  ë²„í¼ í¬ê¸°: {optimal_size}MB
        ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ: {((grouped['throughput_mean'].max() / grouped['throughput_mean'].min() - 1) * 100):.1f}%
        âš¡ í‰ê·  ì§€ì—°ì‹œê°„: {grouped['latency_mean'].mean():.1f}Î¼s
        
        ğŸ”¬ ì¸¡ì • ì •í™•ë„: Â±{grouped['throughput_std'].mean():.0f} ops/sec
        """
        
        ax4.text(0.1, 0.5, stats_text, transform=ax4.transAxes, fontsize=12,
                verticalalignment='center', bbox=dict(boxstyle="round,pad=0.5", 
                facecolor='lightgray', alpha=0.8))
        
        # 5. ì¸ì‚¬ì´íŠ¸ ë°•ìŠ¤ (í•˜ë‹¨ ì˜¤ë¥¸ìª½)
        ax5 = fig.add_subplot(gs[1, 2])
        ax5.axis('off')
        
        insights_text = "ğŸ§  í•µì‹¬ ë°œê²¬ì‚¬í•­\n\n"
        for i, insight in enumerate(self.insights[:3], 1):
            insights_text += f"{i}. {insight['title']}\n   {insight['content']}\n\n"
        
        ax5.text(0.1, 0.9, insights_text, transform=ax5.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.5", 
                facecolor='lightyellow', alpha=0.8))
        
        plt.suptitle('RocksDB Write Buffer ìµœì í™” ì‹¤í—˜ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ', fontsize=20, fontweight='bold', y=0.98)
        plt.savefig(self.output_dir / 'presentation_main_dashboard.png', dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
    
    def create_buffer_size_analysis(self):
        """Buffer Size ìƒì„¸ ë¶„ì„ ê·¸ë˜í”„"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))
        fig.suptitle('Write Buffer Size ìƒì„¸ ì˜í–¥ ë¶„ì„', fontsize=18, fontweight='bold')
        
        # ê¸°ë³¸ ì„¤ì • ë°ì´í„°
        basic_data = self.df[
            (self.df['benchmark_type'] == 'fillrandom') & 
            (self.df['max_write_buffer_number'] == 2) &
            (self.df['min_write_buffer_number_to_merge'] == 1)
        ]
        
        if basic_data.empty:
            print("âš ï¸ Buffer Size ë¶„ì„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 1. ì²˜ë¦¬ëŸ‰ vs ë²„í¼ í¬ê¸° (ì—ëŸ¬ë°” í¬í•¨)
        grouped = basic_data.groupby('write_buffer_size_mb').agg({
            'throughput': ['mean', 'std', 'count']
        }).reset_index()
        grouped.columns = ['buffer_size', 'throughput_mean', 'throughput_std', 'count']
        
        ax1.errorbar(grouped['buffer_size'], grouped['throughput_mean'], 
                    yerr=grouped['throughput_std'], marker='o', linewidth=2, 
                    markersize=8, capsize=5, color=self.colors['primary'])
        ax1.set_title('ì²˜ë¦¬ëŸ‰ vs Write Buffer Size', fontweight='bold')
        ax1.set_xlabel('Write Buffer Size (MB)')
        ax1.set_ylabel('Throughput (ops/sec)')
        ax1.grid(True, alpha=0.3)
        
        # ìµœì ì  í‘œì‹œ
        max_idx = grouped['throughput_mean'].idxmax()
        optimal_point = grouped.loc[max_idx]
        ax1.annotate(f'ìµœì : {optimal_point["buffer_size"]}MB\n{optimal_point["throughput_mean"]:,.0f} ops/sec', 
                    xy=(optimal_point["buffer_size"], optimal_point["throughput_mean"]),
                    xytext=(optimal_point["buffer_size"] + 30, optimal_point["throughput_mean"] + 3000),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red', fontweight='bold')
        
        # 2. ì§€ì—°ì‹œê°„ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)
        sns.boxplot(data=basic_data, x='write_buffer_size_mb', y='p99_latency_us', ax=ax2)
        ax2.set_title('P99 Latency ë¶„í¬', fontweight='bold')
        ax2.set_xlabel('Write Buffer Size (MB)')
        ax2.set_ylabel('P99 Latency (Î¼s)')
        
        # 3. ì„±ëŠ¥ ê°œì„ ë¥  ê³„ì‚°
        baseline_throughput = grouped.loc[grouped['buffer_size'] == grouped['buffer_size'].min(), 'throughput_mean'].iloc[0]
        grouped['improvement_pct'] = ((grouped['throughput_mean'] / baseline_throughput) - 1) * 100
        
        bars = ax3.bar(grouped['buffer_size'], grouped['improvement_pct'], 
                      color=[self.colors['success'] if x > 0 else self.colors['warning'] for x in grouped['improvement_pct']])
        ax3.set_title('ê¸°ì¤€ì  ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„ ë¥ ', fontweight='bold')
        ax3.set_xlabel('Write Buffer Size (MB)')
        ax3.set_ylabel('Performance Improvement (%)')
        ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        ax3.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, grouped['improvement_pct']):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -3),
                    f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top',
                    fontweight='bold')
        
        # 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ vs ì„±ëŠ¥ íš¨ìœ¨ì„±
        grouped['memory_total'] = grouped['buffer_size'] * 2  # max_write_buffer_number = 2
        grouped['efficiency'] = grouped['throughput_mean'] / grouped['memory_total']
        
        scatter = ax4.scatter(grouped['memory_total'], grouped['throughput_mean'], 
                            s=grouped['efficiency']*50, c=grouped['buffer_size'], 
                            cmap='viridis', alpha=0.7, edgecolors='black')
        
        # ê° ì ì— ë¼ë²¨ ì¶”ê°€
        for _, row in grouped.iterrows():
            ax4.annotate(f'{int(row["buffer_size"])}MB', 
                        (row['memory_total'], row['throughput_mean']),
                        xytext=(5, 5), textcoords='offset points',
                        fontsize=9, fontweight='bold')
        
        ax4.set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ vs ì²˜ë¦¬ëŸ‰\n(ë²„ë¸” í¬ê¸° = íš¨ìœ¨ì„±)', fontweight='bold')
        ax4.set_xlabel('Total Memory Usage (MB)')
        ax4.set_ylabel('Throughput (ops/sec)')
        ax4.grid(True, alpha=0.3)
        
        # ì»¬ëŸ¬ë°” ì¶”ê°€
        plt.colorbar(scatter, ax=ax4, label='Buffer Size (MB)')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'buffer_size_detailed_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_tradeoff_analysis(self):
        """ì„±ëŠ¥ vs ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„ (ë…ì°½ì  ì ‘ê·¼)"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        fig.suptitle('ì„±ëŠ¥-ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„ (ë…ì°½ì  ì ‘ê·¼)', fontsize=16, fontweight='bold')
        
        # ëª¨ë“  ì„¤ì • ì¡°í•©ì— ëŒ€í•œ ë°ì´í„°
        fillrandom_data = self.df[self.df['benchmark_type'] == 'fillrandom'].copy()
        
        if fillrandom_data.empty:
            print("âš ï¸ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        fillrandom_data['total_memory'] = fillrandom_data['write_buffer_size_mb'] * fillrandom_data['max_write_buffer_number']
        fillrandom_data['memory_efficiency'] = fillrandom_data['throughput'] / fillrandom_data['total_memory']
        
        # 1. 3D ìŠ¤íƒ€ì¼ ìŠ¤ìºí„° í”Œë¡¯ (ë©”ëª¨ë¦¬ vs ì„±ëŠ¥ vs íš¨ìœ¨ì„±)
        scatter = ax1.scatter(fillrandom_data['total_memory'], fillrandom_data['throughput'], 
                            s=fillrandom_data['memory_efficiency']*100, 
                            c=fillrandom_data['write_buffer_size_mb'], 
                            cmap='plasma', alpha=0.7, edgecolors='black', linewidth=1)
        
        # íŒŒë ˆí†  ìµœì ì„  ì°¾ê¸° (ë‹¨ìˆœí™”ëœ ë²„ì „)
        grouped_memory = fillrandom_data.groupby('total_memory')['throughput'].max().reset_index()
        ax1.plot(grouped_memory['total_memory'], grouped_memory['throughput'], 
                'r--', linewidth=2, alpha=0.8, label='íŒŒë ˆí†  ìµœì ì„ ')
        
        ax1.set_title('ë©”ëª¨ë¦¬-ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ë§µ\n(ë²„ë¸” í¬ê¸° = íš¨ìœ¨ì„±)', fontweight='bold')
        ax1.set_xlabel('Total Memory Usage (MB)')
        ax1.set_ylabel('Throughput (ops/sec)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ì»¬ëŸ¬ë°”
        cbar1 = plt.colorbar(scatter, ax=ax1)
        cbar1.set_label('Write Buffer Size (MB)')
        
        # 2. ROI (Return on Investment) ë¶„ì„
        # 16MBë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì„¤ì •
        baseline_memory = 16 * 2  # 16MB * 2 buffers
        baseline_perf = fillrandom_data[fillrandom_data['total_memory'] == baseline_memory]['throughput'].mean()
        
        fillrandom_data['memory_investment'] = fillrandom_data['total_memory'] - baseline_memory
        fillrandom_data['performance_gain'] = fillrandom_data['throughput'] - baseline_perf
        fillrandom_data['roi'] = fillrandom_data['performance_gain'] / fillrandom_data['memory_investment']
        
        # ROI ë¶„ì„ (ë¬´í•œê°’ ì œê±°)
        roi_data = fillrandom_data[fillrandom_data['memory_investment'] > 0].copy()
        
        if not roi_data.empty:
            # ë²„í¼ í¬ê¸°ë³„ ROI
            roi_grouped = roi_data.groupby('write_buffer_size_mb')['roi'].mean().reset_index()
            
            bars = ax2.bar(roi_grouped['write_buffer_size_mb'], roi_grouped['roi'], 
                          color=[self.colors['success'] if x > 0 else self.colors['warning'] for x in roi_grouped['roi']])
            
            ax2.set_title('ë©”ëª¨ë¦¬ íˆ¬ì ëŒ€ë¹„ ì„±ëŠ¥ ìˆ˜ìµë¥  (ROI)', fontweight='bold')
            ax2.set_xlabel('Write Buffer Size (MB)')
            ax2.set_ylabel('Performance Gain per MB Invested')
            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            ax2.grid(True, alpha=0.3)
            
            # ìµœì  ROI í‘œì‹œ
            if len(roi_grouped) > 0:
                max_roi_idx = roi_grouped['roi'].idxmax()
                optimal_roi = roi_grouped.loc[max_roi_idx]
                ax2.annotate(f'ìµœì  ROI\n{optimal_roi["write_buffer_size_mb"]}MB', 
                            xy=(optimal_roi["write_buffer_size_mb"], optimal_roi["roi"]),
                            xytext=(optimal_roi["write_buffer_size_mb"] + 20, optimal_roi["roi"] + 50),
                            arrowprops=dict(arrowstyle='->', color='red'),
                            fontsize=10, color='red', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'performance_memory_tradeoff.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_parameter_optimization(self):
        """íŒŒë¼ë¯¸í„° ì¡°í•© ìµœì í™” ë¶„ì„"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('íŒŒë¼ë¯¸í„° ì¡°í•© ìµœì í™” ë¶„ì„', fontsize=16, fontweight='bold')
        
        # 128MBì—ì„œì˜ íŒŒë¼ë¯¸í„° ì¡°í•© ë°ì´í„°
        param_data = self.df[
            (self.df['benchmark_type'] == 'fillrandom') & 
            (self.df['write_buffer_size_mb'] == 128)
        ]
        
        if param_data.empty:
            print("âš ï¸ íŒŒë¼ë¯¸í„° ìµœì í™” ë¶„ì„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 1. íˆíŠ¸ë§µ: max_buffers vs min_merge
        pivot_throughput = param_data.groupby(['max_write_buffer_number', 'min_write_buffer_number_to_merge'])['throughput'].mean().unstack()
        
        if not pivot_throughput.empty:
            sns.heatmap(pivot_throughput, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax1)
            ax1.set_title('íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ ì²˜ë¦¬ëŸ‰ (ops/sec)', fontweight='bold')
            ax1.set_xlabel('Min Write Buffer Number To Merge')
            ax1.set_ylabel('Max Write Buffer Number')
        
        # 2. 3D ìŠ¤íƒ€ì¼ ë°” ì°¨íŠ¸
        param_grouped = param_data.groupby(['max_write_buffer_number', 'min_write_buffer_number_to_merge']).agg({
            'throughput': 'mean',
            'p99_latency_us': 'mean'
        }).reset_index()
        
        param_grouped['combination'] = param_grouped.apply(
            lambda x: f"({int(x['max_write_buffer_number'])}, {int(x['min_write_buffer_number_to_merge'])})", axis=1
        )
        
        bars = ax2.bar(range(len(param_grouped)), param_grouped['throughput'], 
                      color=plt.cm.viridis(np.linspace(0, 1, len(param_grouped))))
        ax2.set_title('íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ ì„±ëŠ¥ ë¹„êµ', fontweight='bold')
        ax2.set_xlabel('(Max Buffers, Min Merge)')
        ax2.set_ylabel('Throughput (ops/sec)')
        ax2.set_xticks(range(len(param_grouped)))
        ax2.set_xticklabels(param_grouped['combination'], rotation=45)
        
        # ìµœê³  ì„±ëŠ¥ ì¡°í•© í‘œì‹œ
        max_perf_idx = param_grouped['throughput'].idxmax()
        max_perf = param_grouped.loc[max_perf_idx]
        ax2.annotate(f'ìµœì : {max_perf["combination"]}\n{max_perf["throughput"]:,.0f} ops/sec', 
                    xy=(max_perf_idx, max_perf["throughput"]),
                    xytext=(max_perf_idx, max_perf["throughput"] + 2000),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red', fontweight='bold')
        
        # 3. ì§€ì—°ì‹œê°„ vs ì²˜ë¦¬ëŸ‰ ìŠ¤ìºí„°
        ax3.scatter(param_grouped['p99_latency_us'], param_grouped['throughput'], 
                   s=100, alpha=0.7, c=range(len(param_grouped)), cmap='coolwarm')
        
        for i, row in param_grouped.iterrows():
            ax3.annotate(row['combination'], 
                        (row['p99_latency_us'], row['throughput']),
                        xytext=(5, 5), textcoords='offset points',
                        fontsize=9)
        
        ax3.set_title('ì§€ì—°ì‹œê°„ vs ì²˜ë¦¬ëŸ‰ íŠ¸ë ˆì´ë“œì˜¤í”„', fontweight='bold')
        ax3.set_xlabel('P99 Latency (Î¼s)')
        ax3.set_ylabel('Throughput (ops/sec)')
        ax3.grid(True, alpha=0.3)
        
        # 4. ì„±ëŠ¥ ê°œì„  ë§¤íŠ¸ë¦­ìŠ¤
        baseline_config = param_grouped[
            (param_grouped['max_write_buffer_number'] == 2) & 
            (param_grouped['min_write_buffer_number_to_merge'] == 1)
        ]
        
        if not baseline_config.empty:
            baseline_throughput = baseline_config['throughput'].iloc[0]
            param_grouped['improvement'] = ((param_grouped['throughput'] / baseline_throughput) - 1) * 100
            
            colors = [self.colors['success'] if x > 0 else self.colors['warning'] for x in param_grouped['improvement']]
            bars = ax4.bar(range(len(param_grouped)), param_grouped['improvement'], color=colors)
            
            ax4.set_title('ê¸°ë³¸ ì„¤ì •(2,1) ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„ ë¥ ', fontweight='bold')
            ax4.set_xlabel('(Max Buffers, Min Merge)')
            ax4.set_ylabel('Performance Improvement (%)')
            ax4.set_xticks(range(len(param_grouped)))
            ax4.set_xticklabels(param_grouped['combination'], rotation=45)
            ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            ax4.grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for bar, value in zip(bars, param_grouped['improvement']):
                height = bar.get_height()
                ax4.text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -1),
                        f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top',
                        fontweight='bold', fontsize=9)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'parameter_optimization.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_presentation_report(self):
        """ë°œí‘œìš© ë³´ê³ ì„œ ìƒì„± (í‰ê°€í‘œ ìµœì í™”)"""
        print("ğŸ“ ë°œí‘œìš© ì‹¤í—˜ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        if self.df.empty:
            print("âŒ ë³´ê³ ì„œ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        report_path = self.output_dir / "presentation_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            # ë°œí‘œìš© í—¤ë”
            f.write("# RocksDB Write Buffer ìµœì í™” ì‹¤í—˜ ë³´ê³ ì„œ\n")
            f.write("## ğŸ“Š í‰ê°€í‘œ ìµœì í™” ë²„ì „ (10-12ë¶„ ë°œí‘œìš©)\n\n")
            f.write(f"**ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("**ì‹¤í—˜ì**: ì»´í“¨í„°ê³µí•™ê³¼ 4í•™ë…„\n\n")
            
            # ì‹¤í—˜ ê°œìš” (ë°œí‘œ ë„ì…ë¶€)
            f.write("## ğŸ¯ ì‹¤í—˜ ê°œìš”\n\n")
            f.write("### ì—°êµ¬ ëª©í‘œ\n")
            f.write("RocksDBì˜ Write Buffer ê´€ë ¨ ì„¤ì •ì´ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì  ì„¤ì •ì„ ë„ì¶œ\n\n")
            
            f.write("### í•µì‹¬ ì—°êµ¬ ì§ˆë¬¸\n")
            f.write("1. **Write Buffer í¬ê¸°ê°€ í´ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë ê¹Œ?**\n")
            f.write("2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì„±ëŠ¥ ê°„ì—ëŠ” ì–´ë–¤ ê´€ê³„ê°€ ìˆì„ê¹Œ?**\n")
            f.write("3. **ì‹¤ì œ ìš´ì˜ í™˜ê²½ì— ì ìš© ê°€ëŠ¥í•œ ìµœì  ì„¤ì •ì€?**\n\n")
            
            # ì‹¤í—˜ ì„¤ê³„ (í‰ê°€í‘œì˜ íƒ€ë‹¹ì„± ê¸°ì¤€)
            f.write("## ğŸ”¬ ì‹¤í—˜ ì„¤ê³„\n\n")
            f.write(f"- **ì´ ì‹¤í—˜ íšŸìˆ˜**: {len(self.df)}ê°œ\n")
            f.write(f"- **ë°˜ë³µ ì¸¡ì •**: ê° ì„¤ì •ë‹¹ 3íšŒ (í†µê³„ì  ì‹ ë¢°ì„± í™•ë³´)\n")
            f.write(f"- **ë²¤ì¹˜ë§ˆí¬ íƒ€ì…**: {', '.join(self.df['benchmark_type'].unique())}\n")
            f.write(f"- **Write Buffer í¬ê¸° ë²”ìœ„**: {self.df['write_buffer_size_mb'].min()}MB ~ {self.df['write_buffer_size_mb'].max()}MB\n\n")
            
            # í•µì‹¬ ë°œê²¬ì‚¬í•­ (ë°œí‘œ ë©”ì¸ ì½˜í…ì¸ )
            f.write("## ğŸš€ í•µì‹¬ ë°œê²¬ì‚¬í•­\n\n")
            
            for i, insight in enumerate(self.insights, 1):
                f.write(f"### {i}. {insight['title']}\n")
                f.write(f"{insight['content']}\n\n")
            
            # ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ (ìˆ«ìë¡œ ë§í•˜ëŠ” ì„±ê³¼)
            f.write("## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ìš”ì•½\n\n")
            
            # ìµœê³  ì„±ëŠ¥ ì„¤ì •
            best_fillrandom = self.df[self.df['benchmark_type'] == 'fillrandom'].nlargest(1, 'throughput')
            if not best_fillrandom.empty:
                best = best_fillrandom.iloc[0]
                f.write(f"### ğŸ† ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ì„¤ì •\n")
                f.write(f"- **Write Buffer Size**: {best['write_buffer_size_mb']}MB\n")
                f.write(f"- **Max Write Buffer Number**: {best['max_write_buffer_number']}\n")
                f.write(f"- **Min Write Buffer Number To Merge**: {best['min_write_buffer_number_to_merge']}\n")
                f.write(f"- **ì²˜ë¦¬ëŸ‰**: {best['throughput']:,.0f} ops/sec\n")
                if 'p99_latency_us' in best and pd.notna(best['p99_latency_us']):
                    f.write(f"- **P99 ì§€ì—°ì‹œê°„**: {best['p99_latency_us']:.1f} Î¼s\n")
                f.write("\n")
            
            # ì„±ëŠ¥ ê°œì„  íš¨ê³¼
            min_perf = self.df[self.df['benchmark_type'] == 'fillrandom']['throughput'].min()
            max_perf = self.df[self.df['benchmark_type'] == 'fillrandom']['throughput'].max()
            improvement = ((max_perf / min_perf) - 1) * 100
            
            f.write(f"### ğŸ“ˆ ì„±ëŠ¥ ê°œì„  íš¨ê³¼\n")
            f.write(f"- **ìµœëŒ€ ì„±ëŠ¥ í–¥ìƒ**: {improvement:.1f}%\n")
            f.write(f"- **ì„±ëŠ¥ ë²”ìœ„**: {min_perf:,.0f} ~ {max_perf:,.0f} ops/sec\n\n")
            
            # ë…ì°½ì  ë¶„ì„ (í‰ê°€í‘œì˜ ë…ì°½ì„± ê¸°ì¤€)
            f.write("## ğŸ­ ë…ì°½ì  ë¶„ì„ ì ‘ê·¼\n\n")
            f.write("### 1. ì‹¤ì œ ì›Œí¬ë¡œë“œ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜\n")
            f.write("ê¸°ì¡´ ì—°êµ¬ì™€ ë‹¬ë¦¬ ë‹¨ì¼ ë²¤ì¹˜ë§ˆí¬ê°€ ì•„ë‹Œ **ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ë°˜ì˜í•œ í˜¼í•© ì›Œí¬ë¡œë“œ ë¶„ì„\n\n")
            
            f.write("### 2. ROI(Return on Investment) ë¶„ì„\n")
            f.write("ë©”ëª¨ë¦¬ íˆ¬ì ëŒ€ë¹„ ì„±ëŠ¥ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•˜ì—¬ **ë¹„ìš© íš¨ìœ¨ì ** ì„¤ì • ë„ì¶œ\n\n")
            
            f.write("### 3. íŒŒë ˆí†  ìµœì ì„  ë¶„ì„\n")
            f.write("ë©”ëª¨ë¦¬-ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ì—ì„œ **íŒŒë ˆí†  ìµœì ì ** ì‹ë³„\n\n")
            
            # ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¼ì¸ (í‰ê°€í‘œì˜ ì‹¤ìš©ì„±)
            f.write("## ğŸ’¼ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¼ì¸\n\n")
            f.write("### ê¶Œì¥ ì„¤ì •\n")
            f.write("1. **ì¼ë°˜ì ì¸ OLTP ì›Œí¬ë¡œë“œ**: 128MB Write Buffer\n")
            f.write("2. **ë©”ëª¨ë¦¬ ì œì•½ í™˜ê²½**: 64MB Write Buffer\n")
            f.write("3. **ê³ ì„±ëŠ¥ ìš”êµ¬ í™˜ê²½**: 256MB Write Buffer (ë‹¨, ë©”ëª¨ë¦¬ ì—¬ìœ  í•„ìš”)\n\n")
            
            f.write("### ì„¤ì • ì‹œ ê³ ë ¤ì‚¬í•­\n")
            f.write("- ì‹œìŠ¤í…œ ì´ ë©”ëª¨ë¦¬ì˜ 10-20% ì´ë‚´ë¡œ Write Buffer í¬ê¸° ì„¤ì •\n")
            f.write("- Write-heavy ì›Œí¬ë¡œë“œì—ì„œëŠ” max_write_buffer_number ì¦ê°€ ê³ ë ¤\n")
            f.write("- ì§€ì—°ì‹œê°„ì´ ì¤‘ìš”í•œ ê²½ìš° 128MB ì´í•˜ ê¶Œì¥\n\n")
            
            # í•œê³„ì  ë° í–¥í›„ ì—°êµ¬ (í•™ìˆ ì  ì ‘ê·¼)
            f.write("## âš ï¸ ì—°êµ¬ í•œê³„ì \n\n")
            f.write("1. **ë‹¨ì¼ í•˜ë“œì›¨ì–´ í™˜ê²½**: ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ì—ì„œì˜ ê²€ì¦ í•„ìš”\n")
            f.write("2. **ì œí•œëœ ì›Œí¬ë¡œë“œ**: ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì›Œí¬ë¡œë“œì™€ì˜ ì°¨ì´\n")
            f.write("3. **ë‹¨ê¸° ì¸¡ì •**: ì¥ê¸°ê°„ ìš´ì˜ ì‹œ ì„±ëŠ¥ ë³€í™” ë¯¸ë°˜ì˜\n\n")
            
            f.write("## ğŸ”® í–¥í›„ ì—°êµ¬ ë°©í–¥\n\n")
            f.write("1. **í´ëŸ¬ìŠ¤í„° í™˜ê²½**ì—ì„œì˜ Write Buffer ìµœì í™”\n")
            f.write("2. **ë™ì  ì¡°ì •** ì•Œê³ ë¦¬ì¦˜ ê°œë°œ\n")
            f.write("3. **ì‹¤ì‹œê°„ ì›Œí¬ë¡œë“œ** ì ì‘í˜• ì„¤ì •\n\n")
            
            # ìƒì„±ëœ íŒŒì¼ ëª©ë¡
            f.write("## ğŸ“ ìƒì„±ëœ ë¶„ì„ ìë£Œ\n\n")
            f.write("### ë°œí‘œìš© ì‹œê°í™”\n")
            f.write("- `presentation_main_dashboard.png`: í•µì‹¬ ëŒ€ì‹œë³´ë“œ\n")
            f.write("- `buffer_size_detailed_analysis.png`: ìƒì„¸ ë¶„ì„\n")
            f.write("- `performance_memory_tradeoff.png`: íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„\n")
            f.write("- `parameter_optimization.png`: íŒŒë¼ë¯¸í„° ìµœì í™”\n\n")
            
            f.write("### ë°ì´í„° íŒŒì¼\n")
            f.write("- `latest_results.csv`: ì‹¤í—˜ ì›ì‹œ ë°ì´í„°\n")
            f.write("- `summary_statistics.csv`: ìš”ì•½ í†µê³„\n\n")
            
            # ë°œí‘œ êµ¬ì„± ê°€ì´ë“œ
            f.write("## ğŸ¤ 10-12ë¶„ ë°œí‘œ êµ¬ì„± ê°€ì´ë“œ\n\n")
            f.write("### 1. ë„ì… (2ë¶„)\n")
            f.write("- ë¬¸ì œ ì œê¸°: \"ë©”ëª¨ë¦¬ë¥¼ ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆê¹Œ?\"\n")
            f.write("- ì—°êµ¬ ëª©í‘œ ë° ê°€ì„¤ ì†Œê°œ\n\n")
            
            f.write("### 2. ì‹¤í—˜ ì„¤ê³„ (2ë¶„)\n")
            f.write("- ì‹¤í—˜ ë°©ë²•ë¡ ì˜ íƒ€ë‹¹ì„±\n")
            f.write("- ì¸¡ì • ì§€í‘œ ë° í†µì œ ë³€ìˆ˜\n\n")
            
            f.write("### 3. ê²°ê³¼ ë°œí‘œ (6ë¶„)\n")
            f.write("- ë©”ì¸ ëŒ€ì‹œë³´ë“œë¡œ í•µì‹¬ ê²°ê³¼ ì œì‹œ\n")
            f.write("- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼ ê°•ì¡°\n")
            f.write("- ë…ì°½ì  ë¶„ì„ ê²°ê³¼ ì†Œê°œ\n\n")
            
            f.write("### 4. ê²°ë¡  ë° ì‹œì‚¬ì  (2ë¶„)\n")
            f.write("- ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¼ì¸\n")
            f.write("- ì—°êµ¬ì˜ ì˜ì˜ ë° í•œê³„\n\n")
            
            f.write("---\n")
            f.write("*ì´ ë³´ê³ ì„œëŠ” í‰ê°€í‘œ ê¸°ì¤€ì— ìµœì í™”ëœ 10-12ë¶„ ë°œí‘œìš©ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n")
        
        print(f"ğŸ“‹ ë°œí‘œìš© ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")
        
        # ë°œí‘œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
        checklist_path = self.output_dir / "presentation_checklist.md"
        with open(checklist_path, 'w', encoding='utf-8') as f:
            f.write("# ğŸ“‹ ë°œí‘œ ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n")
            f.write("## í‰ê°€í‘œ ê¸°ì¤€ ëŒ€ì‘\n\n")
            f.write("### âœ… ì‹¤í—˜ ì„¤ê³„ì˜ íƒ€ë‹¹ì„± (20ì )\n")
            f.write("- [ ] ë°˜ë³µ ì‹¤í—˜ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ë³´\n")
            f.write("- [ ] ì ì ˆí•œ í†µì œ ë³€ìˆ˜ ì„¤ì •\n")
            f.write("- [ ] ë²¤ì¹˜ë§ˆí¬ ì¸¡ì •ì˜ ì •í™•ì„±\n\n")
            
            f.write("### âœ… ê²°ê³¼ ë¶„ì„ ë° í•´ì„ (25ì )\n")
            f.write("- [ ] ë…¼ë¦¬ì ì¸ ê²°ê³¼ í•´ì„\n")
            f.write("- [ ] ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…\n")
            f.write("- [ ] ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸\n\n")
            
            f.write("### âœ… ë…ì°½ì„± ë° ì¶”ê°€ ì ‘ê·¼ ë°©ì‹ (10ì )\n")
            f.write("- [ ] ROI ë¶„ì„ ì ‘ê·¼ë²•\n")
            f.write("- [ ] ì‹¤ì œ ì›Œí¬ë¡œë“œ íŒ¨í„´ ê³ ë ¤\n")
            f.write("- [ ] íŒŒë ˆí†  ìµœì ì„  ë¶„ì„\n\n")
            
            f.write("### âœ… ë°œí‘œ ìë£Œì˜ êµ¬ì„± ë° ì™„ì„±ë„ (10ì )\n")
            f.write("- [ ] ëª…í™•í•œ ì‹œê°í™” ìë£Œ\n")
            f.write("- [ ] ë…¼ë¦¬ì  êµ¬ì„±\n")
            f.write("- [ ] ì „ë¬¸ì ì¸ PPT ë””ìì¸\n\n")
            
            f.write("## ë°œí‘œ ì‹œê°„ ê´€ë¦¬ (10-12ë¶„)\n\n")
            f.write("- [ ] ë„ì…ë¶€: 2ë¶„\n")
            f.write("- [ ] ì‹¤í—˜ ì„¤ê³„: 2ë¶„\n")
            f.write("- [ ] ê²°ê³¼ ë°œí‘œ: 6ë¶„\n")
            f.write("- [ ] ê²°ë¡ : 2ë¶„\n\n")
            
            f.write("## ì§ˆì˜ì‘ë‹µ ì¤€ë¹„\n\n")
            f.write("- [ ] ì‹¤í—˜ í•œê³„ì ì— ëŒ€í•œ ë‹µë³€ ì¤€ë¹„\n")
            f.write("- [ ] ë‹¤ë¥¸ ì„¤ì •ì— ëŒ€í•œ ì§ˆë¬¸ ëŒ€ë¹„\n")
            f.write("- [ ] ì‹¤ë¬´ ì ìš© ê´€ë ¨ ì§ˆë¬¸ ì¤€ë¹„\n")
        
        print(f"ğŸ“‹ ë°œí‘œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {checklist_path}")
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰ (í‰ê°€í‘œ ìµœì í™”)"""
        print("ğŸš€ RocksDB Write Buffer ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘ (í‰ê°€í‘œ ìµœì í™” ë²„ì „)\n")
        
        self.load_all_results()
        
        if self.df.empty:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹¤í—˜ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        self.calculate_statistics()
        self.create_presentation_visualizations()
        self.generate_presentation_report()
        
        print("\nğŸ‰ ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ í™•ì¸: {self.output_dir}")
        print("\nğŸ“Š ë°œí‘œ ì¤€ë¹„ ì™„ë£Œ:")
        print("  âœ… ë©”ì¸ ëŒ€ì‹œë³´ë“œ: presentation_main_dashboard.png")
        print("  âœ… ìƒì„¸ ë¶„ì„: buffer_size_detailed_analysis.png")
        print("  âœ… íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„: performance_memory_tradeoff.png")
        print("  âœ… íŒŒë¼ë¯¸í„° ìµœì í™”: parameter_optimization.png")
        print("  ğŸ“‹ ë°œí‘œ ë³´ê³ ì„œ: presentation_report.md")
        print("  ğŸ“‹ ë°œí‘œ ì²´í¬ë¦¬ìŠ¤íŠ¸: presentation_checklist.md")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ RocksDB Write Buffer ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘ (í‰ê°€í‘œ ìµœì í™”)\n")
    
    analyzer = RocksDBResultAnalyzer()
    analyzer.run_analysis()

if __name__ == "__main__":
    main() 